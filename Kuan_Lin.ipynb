{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "6uRueegm8jfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "plAqhyeN8qnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "eyE7Mt8pTFB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")"
      ],
      "metadata": {
        "id": "D2M08TiNTJev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Synonym Replacement\n",
        "def synonym_replacement(text, n=2):\n",
        "    words = text.split()\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "        word = random.choice(words)\n",
        "        synonyms = wordnet.synsets(word)\n",
        "        if synonyms:\n",
        "            new_word = synonyms[0].lemmas()[0].name()\n",
        "            new_words = [new_word if w == word else w for w in new_words]\n",
        "    return \" \".join(new_words)\n",
        "\n",
        "# Sentence Shuffling\n",
        "def shuffle_sentences(text):\n",
        "    sentences = text.split(\". \")\n",
        "    random.shuffle(sentences)\n",
        "    return \". \".join(sentences)\n"
      ],
      "metadata": {
        "id": "ky6ZOpKOTLTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "OwZnQX3Kf2a1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMI1EFpe6Xog"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Train Data\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Datasets/training.csv\")\n",
        "\n",
        "train_df[\"title\"] = train_df[\"title\"].str.lower()\n",
        "train_df[\"abstract\"] = train_df[\"abstract\"].str.lower()\n",
        "\n",
        "# Merge title + abstract\n",
        "train_df[\"text\"] = train_df[\"title\"] + \" \" + train_df[\"abstract\"]\n",
        "\n",
        "# Ensure category labels are converted to integers\n",
        "label_map = {label: idx for idx, label in enumerate(train_df[\"category\"].unique())}\n",
        "train_df[\"label\"] = train_df[\"category\"].map(label_map)\n",
        "\n",
        "\n",
        "# for key, value in label_map.items():\n",
        "#     print(f\"{key}: {value}\")\n",
        "\n",
        "# Check class distribution before oversampling\n",
        "print(\"Before Oversampling:\")\n",
        "print(train_df[\"category\"].value_counts(normalize=True))\n",
        "\n",
        "# Find the largest category count\n",
        "max_size = train_df[\"category\"].value_counts().max()\n",
        "\n",
        "# Oversample all classes to match the largest category and apply augmentation\n",
        "df_balanced = []\n",
        "for category in train_df[\"category\"].unique():\n",
        "    df_subset = train_df[train_df[\"category\"] == category]\n",
        "    df_upsampled = resample(df_subset, replace=True, n_samples=max_size, random_state=42)\n",
        "    augmented_data = df_upsampled.copy()\n",
        "\n",
        "    for i in range(len(augmented_data)):\n",
        "        if random.random() > 0.5:\n",
        "            choice = random.choice([\"synonym\", \"shuffle\"])\n",
        "            if choice == \"synonym\":\n",
        "                augmented_data.iloc[i, augmented_data.columns.get_loc(\"text\")] = synonym_replacement(df_upsampled.iloc[i][\"text\"])\n",
        "            elif choice == \"shuffle\":\n",
        "                augmented_data.iloc[i, augmented_data.columns.get_loc(\"text\")] = shuffle_sentences(df_upsampled.iloc[i][\"text\"])\n",
        "\n",
        "    df_balanced.append(augmented_data)\n",
        "\n",
        "# Combine balanced and augmented dataset\n",
        "balanced_df = pd.concat(df_balanced)\n",
        "\n",
        "# Shuffle dataset\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# Check new class distribution\n",
        "print(\"\\nAfter Oversampling:\")\n",
        "print(balanced_df[\"category\"].value_counts(normalize=True))\n",
        "\n",
        "\n",
        "# Stratified 80-20 split to maintain equal class distribution\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    balanced_df[\"text\"],\n",
        "    balanced_df[\"label\"],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=balanced_df[\"label\"]  # Ensures equal class distribution\n",
        ")\n",
        "\n",
        "# Check category distribution in training set\n",
        "print(\"Training set distribution:\")\n",
        "print(pd.Series(train_labels).value_counts(normalize=True))\n",
        "\n",
        "# Check category distribution in validation set\n",
        "print(\"\\nValidation set distribution:\")\n",
        "print(pd.Series(val_labels).value_counts(normalize=True))\n",
        "\n",
        "\n",
        "\n",
        "# Convert to Hugging Face dataset format\n",
        "train_dataset = Dataset.from_dict({\"text\": train_texts.tolist(), \"label\": train_labels.tolist()})\n",
        "val_dataset = Dataset.from_dict({\"text\": val_texts.tolist(), \"label\": val_labels.tolist()})\n",
        "\n",
        "print(f\"Training set: {len(train_dataset)} samples\")\n",
        "print(f\"Validation set: {len(val_dataset)} samples\")\n",
        "print(\"Dataset Loaded Successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning pretrained model**"
      ],
      "metadata": {
        "id": "-iqZCr20f-0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v1\"  # Zero-shot model\n",
        "# model_name = \"microsoft/deberta-v3-large\"  # Zero-shot model\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map), ignore_mismatched_sizes=True)\n",
        "\n",
        "print(\"Model loaded for fine-tuning\")"
      ],
      "metadata": {
        "id": "BilL3a4t8Dsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "print(\"Tokenization complete\")"
      ],
      "metadata": {
        "id": "sEcSW5Qw8D0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=6,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "dxsORRqc8D3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluated Model through validation dataset**"
      ],
      "metadata": {
        "id": "TjFh6DBegRPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "QmQ8XiYS8D5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_eval_preds = trainer.predict(tokenized_val_dataset)\n",
        "logits, labels = raw_eval_preds.predictions, raw_eval_preds.label_ids\n",
        "\n",
        "# Compute accuracy & F1\n",
        "metrics = compute_metrics((logits, labels))\n",
        "print(\"Computed Metrics:\", metrics)"
      ],
      "metadata": {
        "id": "MqAXgr4Q8Zqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "c5jp9z6EgX8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model & tokenizer\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Datasets/fine_tuned_model1\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Datasets/fine_tuned_model1\")\n",
        "\n",
        "print(\"Fine-tuned model2 saved!\")\n"
      ],
      "metadata": {
        "id": "tF5Tgtuq8D8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Random text to ensure the model integerity before truly predict testing file**"
      ],
      "metadata": {
        "id": "_zPekgdrga82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model\n",
        "classifier = pipeline(\"text-classification\", model=\"/content/drive/MyDrive/Colab Notebooks/Datasets/fine_tuned_model1\", tokenizer=tokenizer)\n",
        "\n",
        "# Predict on new text\n",
        "# text = \"Quantum entanglement is key to secure communication.\"\n",
        "text = \"The present invention involves a quantum computing structure, comprising: one or more logical qubits, which is encoded into a plurality of superconducting qubits; and each of the logical qubits comprises at least one operating qubit and at least one ancilla qubit. Also provided is a method of quantum computing, comprising: performing encoded quantum computing operations with logical qubits that are encoded into superconducting operating qubits and superconducting ancilla qubits. The present invention further involves a method of error correction for a quantum computing structure comprising: presenting a plurality of logical qubits, each of which comprises an operating physical qubit and an ancilla physical qubit, wherein the logical states of the plurality of logical qubits are formed from a tensor product of the states of the operating and ancilla qubits; and wherein the states of the ancilla physical qubits are suppressed; and applying strong pulses to the grouping of logical qubits.\"\n",
        "prediction = classifier(text)\n",
        "\n",
        "print(\"Predicted Category:\", prediction)\n",
        "\n",
        "num_labels = model.config.num_labels\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "T-0eQ1Lu8D-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict testing file**"
      ],
      "metadata": {
        "id": "liesaRJ2gr7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Datasets/fine_tuned_model1\"\n",
        "classifier = pipeline(\"text-classification\", model=model_path, tokenizer=model_path, return_all_scores=False)\n",
        "\n",
        "# Load test dataset\n",
        "test_file_path = \"/content/drive/MyDrive/Colab Notebooks/Datasets/testing.csv\"  # Update with actual path\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "if \"title\" in test_df.columns and \"abstract\" in test_df.columns:\n",
        "    test_df[\"text\"] = test_df[\"title\"] + \" \" + test_df[\"abstract\"]\n",
        "else:\n",
        "    print(\"Error: Ensure your CSV file contains 'title' and 'abstract' columns.\")\n",
        "\n",
        "# Apply predictions to the entire dataset\n",
        "test_df[[\"predicted_category\", \"confidence\"]] = test_df[\"text\"].apply(\n",
        "    lambda x: pd.Series({\n",
        "        \"predicted_category\": classifier(x)[0]['label'],  # Predicted label\n",
        "        \"confidence\": classifier(x)[0]['score']  # Confidence probability\n",
        "    })\n",
        ")\n",
        "\n",
        "# Convert `LABEL_X` to an integer\n",
        "test_df[\"predicted_category\"] = test_df[\"predicted_category\"].apply(lambda x: int(x.split(\"_\")[-1]))  # Convert `LABEL_1` â†’ 1\n",
        "\n",
        "# Reverse the dictionary\n",
        "label_map_reverse = {v: k for k, v in label_map.items()}\n",
        "\n",
        "# Map numeric labels back to their category names\n",
        "test_df[\"predicted_category\"] = test_df[\"predicted_category\"].map(label_map_reverse)\n",
        "\n",
        "test_df.drop(columns=[\"text\"], inplace=True)\n",
        "\n",
        "# Save file with predictions\n",
        "output_file = \"/content/drive/MyDrive/Colab Notebooks/Datasets/Kuan_Lin_testing.csv\"\n",
        "test_df.to_csv(output_file, index=False)\n",
        "print(f\"Predictions saved to: {output_file}\")"
      ],
      "metadata": {
        "id": "q3Sl7t2yTrPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Double check format and output**"
      ],
      "metadata": {
        "id": "9ygGPBxPgz87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Datasets/test_data_with_predictions1.csv\")\n",
        "print(df[\"predicted_category\"].head())"
      ],
      "metadata": {
        "id": "uNCJh1-UfmvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}